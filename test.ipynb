{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b4f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging_config import setup_logging\n",
    "from bhavcopy_utils import file_exists\n",
    "import os\n",
    "\n",
    "NSE_base_url = os.getenv('NSE_base_url')\n",
    "bhav_copy_archive_path = os.getenv(\"bhav_copy_archive_path\")\n",
    "INDEX_LIST = os.getenv('INDEX_LIST').split(',')\n",
    "environment = os.getenv('APP_ENV', 'DEBUG')\n",
    "\n",
    "NSE_PRICE_DATA_OPEN = os.getenv(\"NSE_PRICE_DATA_OPEN\")\n",
    "NSE_PRICE_DATA_HIGH = os.getenv(\"NSE_PRICE_DATA_HIGH\")\n",
    "NSE_PRICE_DATA_LOW = os.getenv(\"NSE_PRICE_DATA_LOW\")\n",
    "NSE_PRICE_DATA_CLOSE = os.getenv(\"NSE_PRICE_DATA_CLOSE\")\n",
    "NSE_PRICE_DATA_DELIV_QTY = os.getenv(\"NSE_PRICE_DATA_DELIV_QTY\")\n",
    "NSE_PRICE_DATA_DELIV_PER = os.getenv(\"NSE_PRICE_DATA_DELIV_PER\")\n",
    "NSE_VOLUME_DATA = os.getenv(\"NSE_VOLUME_DATA\")\n",
    "\n",
    "\n",
    "logger = setup_logging(logger_name='price_loger',\n",
    "                       info_file='specific_info.log', \n",
    "                        warning_file='specific_warning.log', \n",
    "                        error_file='specific_error.log', \n",
    "                        environment=environment)\n",
    "\n",
    "o_logger = h_logger = l_logger = c_logger = v_logger = d_logger = dp_logger = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5929077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE_PRICE_DATA_OPEN.csv\n"
     ]
    }
   ],
   "source": [
    "print(NSE_PRICE_DATA_OPEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "405b68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Column Configurations ========= #\n",
    "# Base input column names from NSE CSV\n",
    "base_columns = {\n",
    "    \"open\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' OPEN_PRICE'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'OPEN_PRICE'],\n",
    "        \"pivot_value\": 'OPEN_PRICE',\n",
    "        \"outfile\": NSE_PRICE_DATA_OPEN,\n",
    "        \"logger\": o_logger\n",
    "    },\n",
    "    \"high\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' HIGH_PRICE'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'HIGH_PRICE'],\n",
    "        \"pivot_value\": 'HIGH_PRICE',\n",
    "        \"outfile\": NSE_PRICE_DATA_HIGH,\n",
    "        \"logger\": h_logger\n",
    "    },\n",
    "    \"low\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' LOW_PRICE'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'LOW_PRICE'],\n",
    "        \"pivot_value\": 'LOW_PRICE',\n",
    "        \"outfile\": NSE_PRICE_DATA_LOW,\n",
    "        \"logger\": l_logger\n",
    "    },\n",
    "    \"close\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' CLOSE_PRICE'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'CLOSE_PRICE'],\n",
    "        \"pivot_value\": 'CLOSE_PRICE',\n",
    "        \"outfile\": NSE_PRICE_DATA_CLOSE,\n",
    "        \"logger\": c_logger\n",
    "    },\n",
    "    \"volume\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' TTL_TRD_QNTY'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'TTL_TRD_QNTY'],\n",
    "        \"pivot_value\": 'TTL_TRD_QNTY',\n",
    "        \"outfile\": NSE_VOLUME_DATA,\n",
    "        \"logger\": v_logger\n",
    "    },\n",
    "    \"delivery_qty\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' DELIV_QTY'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'DELIV_QTY'],\n",
    "        \"pivot_value\": 'DELIV_QTY',\n",
    "        \"outfile\": NSE_PRICE_DATA_DELIV_QTY,\n",
    "        \"logger\": d_logger\n",
    "    },\n",
    "    \"delivery_per\": {\n",
    "        \"required\": ['SYMBOL',' SERIES', ' DATE1', ' DELIV_PER'],\n",
    "        \"renamed\": ['SYMBOL', 'SERIES', 'Date', 'DELIV_PER'],\n",
    "        \"pivot_value\": 'DELIV_PER',\n",
    "        \"outfile\": NSE_PRICE_DATA_DELIV_PER,\n",
    "        \"logger\": dp_logger\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d34907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_or_add_master_data(filepath, date, config_key):\n",
    "    config = base_columns[config_key]\n",
    "\n",
    "    print(config)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df[config[\"required\"]]\n",
    "    df.columns = config[\"renamed\"]\n",
    "\n",
    "    # Keep only EQ, BE series\n",
    "    df = df[(df['SERIES'] == ' EQ') | (df['SERIES'] == ' BE')]\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)\n",
    "\n",
    "    pivot_data = df.pivot(columns='SYMBOL', index='Date', values=config[\"pivot_value\"])\n",
    "    pivot_data.reset_index(inplace=True)\n",
    "    pivot_data['Date'] = pd.to_datetime(pivot_data['Date'])\n",
    "\n",
    "    outfile = config[\"outfile\"]\n",
    "    print(outfile)\n",
    "    logger = config[\"logger\"]\n",
    "\n",
    "    if file_exists(outfile):\n",
    "        nse_data = pd.read_csv(outfile)\n",
    "    else:\n",
    "        nse_data = pd.DataFrame(columns=['Date'] + list(df['SYMBOL'].values))\n",
    "\n",
    "    if pivot_data.empty:\n",
    "        logger.critical(f\"Pivot data is empty. Please check input. - {date}\")\n",
    "        return False\n",
    "\n",
    "    # Handle missing new stocks\n",
    "    missing_columns = set(pivot_data.columns) - set(nse_data.columns)\n",
    "    if len(missing_columns) > 0:\n",
    "        for col in missing_columns:\n",
    "            logger.warning(f\"Stock missing in nse_data: {col}  - {date}\")\n",
    "        missing_data = pd.DataFrame({col: pd.NA for col in missing_columns}, index=nse_data.index)\n",
    "        nse_data = pd.concat([nse_data, missing_data], axis=1)\n",
    "\n",
    "    # Handle missing old stocks\n",
    "    missing_columns_pivot = set(nse_data.columns) - set(pivot_data.columns)\n",
    "    if len(missing_columns_pivot) > 0:\n",
    "        num_rows = pivot_data.shape[0]\n",
    "        new_columns_df = pd.DataFrame({col: [np.nan]*num_rows for col in missing_columns_pivot})\n",
    "        for col in missing_columns_pivot:\n",
    "            logger.warning(f\"Stock missing in pivot_data: {col}  - {date}\")\n",
    "        pivot_data = pd.concat([pivot_data, new_columns_df], axis=1)\n",
    "\n",
    "    # Merge\n",
    "    nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
    "\n",
    "    nse_data['Date'] = pd.to_datetime(nse_data['Date'])\n",
    "    nse_data = nse_data.sort_values(by='Date')\n",
    "    nse_data = nse_data.groupby('Date', as_index=False).first()\n",
    "    nse_data = nse_data.copy()\n",
    "\n",
    "    # Fill NaN only for volume-like data\n",
    "    if config_key in ['volume']:\n",
    "        nse_data.fillna(0, inplace=True)\n",
    "\n",
    "    nse_data.to_csv(outfile, index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd50a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' OPEN_PRICE'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'OPEN_PRICE'], 'pivot_value': 'OPEN_PRICE', 'outfile': 'NSE_PRICE_DATA_OPEN.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_PRICE_DATA_OPEN.csv\n",
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' HIGH_PRICE'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'HIGH_PRICE'], 'pivot_value': 'HIGH_PRICE', 'outfile': 'NSE_PRICE_DATA_HIGH.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_PRICE_DATA_HIGH.csv\n",
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' LOW_PRICE'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'LOW_PRICE'], 'pivot_value': 'LOW_PRICE', 'outfile': 'NSE_PRICE_DATA_LOW.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_PRICE_DATA_LOW.csv\n",
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' CLOSE_PRICE'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'CLOSE_PRICE'], 'pivot_value': 'CLOSE_PRICE', 'outfile': 'NSE_PRICE_DATA_CLOSE.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_PRICE_DATA_CLOSE.csv\n",
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' TTL_TRD_QNTY'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'TTL_TRD_QNTY'], 'pivot_value': 'TTL_TRD_QNTY', 'outfile': 'NSE_VOLUME_DATA.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_VOLUME_DATA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  nse_data = nse_data.groupby('Date', as_index=False).first()\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' DELIV_QTY'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'DELIV_QTY'], 'pivot_value': 'DELIV_QTY', 'outfile': 'NSE_PRICE_DATA_DELIV_QTY.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_PRICE_DATA_DELIV_QTY.csv\n",
      "{'required': ['SYMBOL', ' SERIES', ' DATE1', ' DELIV_PER'], 'renamed': ['SYMBOL', 'SERIES', 'Date', 'DELIV_PER'], 'pivot_value': 'DELIV_PER', 'outfile': 'NSE_PRICE_DATA_DELIV_PER.csv', 'logger': <Logger price_loger (DEBUG)>}\n",
      "NSE_PRICE_DATA_DELIV_PER.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  nse_data = nse_data.groupby('Date', as_index=False).first()\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nse_data = pd.concat([nse_data, pivot_data], ignore_index=True)\n",
      "/var/folders/pr/5qrnbjyd35g7js8x5y3q4g300000gn/T/ipykernel_49065/1831065742.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  nse_data = nse_data.groupby('Date', as_index=False).first()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/Users/shubhgoela/Downloads/sec_bhavdata_full_14082025.csv'\n",
    "\n",
    "date = '14-08-2025'\n",
    "create_or_add_master_data(filepath, date, \"open\")\n",
    "create_or_add_master_data(filepath, date, \"high\")\n",
    "create_or_add_master_data(filepath, date, \"low\")\n",
    "create_or_add_master_data(filepath, date, \"close\")\n",
    "create_or_add_master_data(filepath, date, \"volume\")\n",
    "# create_or_add_master_data(filepath, date, \"turnover\")\n",
    "create_or_add_master_data(filepath, date, \"delivery_qty\")\n",
    "create_or_add_master_data(filepath, date, \"delivery_per\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37317720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
